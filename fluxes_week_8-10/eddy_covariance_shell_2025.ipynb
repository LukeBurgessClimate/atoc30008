{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eddy Covariance Method for calculating fluxes\n",
    "\n",
    "In lecture 3, you learnt about how vertical fluxes can be expressed as the sum of all the transport by individual eddies. \n",
    "\n",
    "For example, the sensible heat flux can be written as:\n",
    "\n",
    "$Q_H = \\rho c_p \\overline{w' \\theta'}$\n",
    "\n",
    "The latent heat flux can be written as:\n",
    "\n",
    "$Q_E = \\rho L_v \\overline{w' q'}$\n",
    "\n",
    "This assignment has two parts:\n",
    "1. You're going to calculate $Q_H$ and $Q_E$ for a 24 hour period, using turbulent flux measurements. The measurements are taken from a measurement tower that was formerly installed in the Wombat State Forest (Northwest of Melbourne). \n",
    "\n",
    "2. You will calculate the surface energy balance terms for a year of measurements of $Q_H$ and $Q_E$, $Q_G$ $LW \\downarrow$, $SW \\downarrow$, $LW \\uparrow$ and $SW \\uparrow$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Eddy Covariance Calculation\n",
    "\n",
    "Question 1: Follow the steps in the Jupyter notebook to calculate $Q_H$ and $Q_E$. Include all the requested plots in your report. Present your results as a graph with $Q_H$ and $Q_E$ on the same axes. [4 marks]\n",
    "\n",
    "Question 2: Describe what you think the clouds were like on this day and sketch what you think the incoming short-wave radiation might have looked like. [2 marks]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Surface Energy Balance\n",
    "\n",
    "Question 1: Write down the equation for the surface energy balance [1 mark]\n",
    "\n",
    "Question 2: Follow the steps in the Jupyter notebook to calculate the seven terms of the average surface energy balance. Find a meaningful way to present your results and test the hypothesis that the sum of the radiative fluxes are balanced by the sum of the sensible, latent and ground heat fluxes. [3 marks]\n",
    "\n",
    "Question 3: Do the terms balance? Why / Why not? [1 mark]\n",
    "\n",
    "Question 4: These fluxes were measured at a height of 30 m above the ground, so that the measurement mast extends out of the forest canopy. How might the results have changed if they had been measured at the forest floor?  [1 mark]\n",
    "\n",
    "Question 5: Choose one day from the year, and plot the surface energy balance for that specific day. Does it balance when you look at a single day? What might cause errors in the balance? [2 marks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just run this! This loads some packages that we're going to use\n",
    "import pandas\n",
    "import numpy as np\n",
    "import datetime as datetime\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>TIMESTAMP</th>\n",
       "      <th>Vertical_velocity</th>\n",
       "      <th>Virtual_Temp</th>\n",
       "      <th>Pressure</th>\n",
       "      <th>Vapour_Pressure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2019-03-08 00:00:00.000</td>\n",
       "      <td>-0.23175</td>\n",
       "      <td>15.40259</td>\n",
       "      <td>93.37927</td>\n",
       "      <td>0.442335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-03-08 00:00:00.200</td>\n",
       "      <td>-0.63725</td>\n",
       "      <td>15.52631</td>\n",
       "      <td>93.43839</td>\n",
       "      <td>0.445633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2019-03-08 00:00:00.300</td>\n",
       "      <td>-0.53350</td>\n",
       "      <td>15.58398</td>\n",
       "      <td>93.40527</td>\n",
       "      <td>0.445690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2019-03-08 00:00:00.400</td>\n",
       "      <td>-0.58875</td>\n",
       "      <td>15.41278</td>\n",
       "      <td>93.41237</td>\n",
       "      <td>0.443708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2019-03-08 00:00:00.500</td>\n",
       "      <td>-0.07800</td>\n",
       "      <td>15.25351</td>\n",
       "      <td>93.41237</td>\n",
       "      <td>0.447943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>820270</th>\n",
       "      <td>820270</td>\n",
       "      <td>2019-03-08 23:59:59.500</td>\n",
       "      <td>0.12575</td>\n",
       "      <td>14.98248</td>\n",
       "      <td>93.43839</td>\n",
       "      <td>0.757567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>820271</th>\n",
       "      <td>820271</td>\n",
       "      <td>2019-03-08 23:59:59.600</td>\n",
       "      <td>0.00425</td>\n",
       "      <td>14.99432</td>\n",
       "      <td>93.43839</td>\n",
       "      <td>0.754179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>820272</th>\n",
       "      <td>820272</td>\n",
       "      <td>2019-03-08 23:59:59.700</td>\n",
       "      <td>-0.07825</td>\n",
       "      <td>14.99600</td>\n",
       "      <td>93.43839</td>\n",
       "      <td>0.755957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>820273</th>\n",
       "      <td>820273</td>\n",
       "      <td>2019-03-08 23:59:59.800</td>\n",
       "      <td>-0.09575</td>\n",
       "      <td>15.06714</td>\n",
       "      <td>93.46440</td>\n",
       "      <td>0.755958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>820274</th>\n",
       "      <td>820274</td>\n",
       "      <td>2019-03-08 23:59:59.900</td>\n",
       "      <td>0.19450</td>\n",
       "      <td>14.94351</td>\n",
       "      <td>93.43839</td>\n",
       "      <td>0.755263</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>820275 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0               TIMESTAMP  Vertical_velocity  Virtual_Temp  \\\n",
       "0                0 2019-03-08 00:00:00.000           -0.23175      15.40259   \n",
       "1                1 2019-03-08 00:00:00.200           -0.63725      15.52631   \n",
       "2                2 2019-03-08 00:00:00.300           -0.53350      15.58398   \n",
       "3                3 2019-03-08 00:00:00.400           -0.58875      15.41278   \n",
       "4                4 2019-03-08 00:00:00.500           -0.07800      15.25351   \n",
       "...            ...                     ...                ...           ...   \n",
       "820270      820270 2019-03-08 23:59:59.500            0.12575      14.98248   \n",
       "820271      820271 2019-03-08 23:59:59.600            0.00425      14.99432   \n",
       "820272      820272 2019-03-08 23:59:59.700           -0.07825      14.99600   \n",
       "820273      820273 2019-03-08 23:59:59.800           -0.09575      15.06714   \n",
       "820274      820274 2019-03-08 23:59:59.900            0.19450      14.94351   \n",
       "\n",
       "        Pressure  Vapour_Pressure  \n",
       "0       93.37927         0.442335  \n",
       "1       93.43839         0.445633  \n",
       "2       93.40527         0.445690  \n",
       "3       93.41237         0.443708  \n",
       "4       93.41237         0.447943  \n",
       "...          ...              ...  \n",
       "820270  93.43839         0.757567  \n",
       "820271  93.43839         0.754179  \n",
       "820272  93.43839         0.755957  \n",
       "820273  93.46440         0.755958  \n",
       "820274  93.43839         0.755263  \n",
       "\n",
       "[820275 rows x 6 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here we load the data\n",
    "df = pandas.read_csv('/home/workbooks/fluxes_week8-9/Fluxes2024.csv', parse_dates=['TIMESTAMP'])\n",
    "\n",
    "# Print the dataframe to have a look at which variables it contains:\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-3-445ffea344f3>, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-3-445ffea344f3>\"\u001b[0;36m, line \u001b[0;32m4\u001b[0m\n\u001b[0;31m    mixing_ratio =\u001b[0m\n\u001b[0m                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# First, you need to calculate the mixing ratio and the virtual potential temperature. \n",
    "# Note that Pressure and Vapour pressure are both in kPa, so you have to multiply by 1000 to get Pa. \n",
    "# For the mixing ratio, see lecture 2, slide 36\n",
    "mixing_ratio = \n",
    "theta = \n",
    "\n",
    "# Add them to the dataframe:\n",
    "df['Mixing_ratio'] = mixing_ratio\n",
    "df['Theta'] = theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data length and missing data\n",
    "You'll notice that your data is slightly shorter than the expected length of 864000. That's because of missing datapoints, which is an annoying thing that almost always happens with 'real world' data. We're going to deal with that in the analysis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Half hour averaging function ##\n",
    "\n",
    "We're going to have to do this a few times in this analysis, so let's make a function. Study this function carefully, because the structure of this will help you in the other steps of the analysis. I've done this for you, to get you started. \n",
    "\n",
    "Running this function just builds your halfhour averaging 'machine', but it won't actually do anything until you put some data into it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_half_hour_avs(data, var): # <- don't forget the : after your function definition\n",
    "    '''\n",
    "    Half hour averaging function: \n",
    "    Inputs: The data frame, and the variable that we would like to return the half-hourly values of\n",
    "    Outputs: The half-hour averages.\n",
    "    '''\n",
    "    \n",
    "    # Define an empty array to store hour half-hour averages in\n",
    "\n",
    "    halfhourvar = []\n",
    "    halfhourts = []\n",
    "\n",
    "    # Let's start at the start of the dataset\n",
    "    tstart = data.TIMESTAMP[0]\n",
    "    \n",
    "    # Get the 'TIMESTAMP' and var columns from the dataframe.\n",
    "    data = data[['TIMESTAMP', var]]\n",
    "\n",
    "    # Now, we're going to loop through each half hour of the 24-hour period. \n",
    "    for nseg in np.arange(0,48):\n",
    "        \n",
    "        # The end of the half-hour period is 30 minutes after the start of the half-hour period\n",
    "        tend = tstart + pandas.Timedelta(minutes=30)\n",
    "        #print('Calculating averages for half hour between', np.str(tstart), ' and ', np.str(tend))\n",
    "\n",
    "        # Make a mask for the 30 minute period between dstart and dend\n",
    "        mask = (data['TIMESTAMP'] >= tstart) & (data['TIMESTAMP'] < tend)\n",
    "        \n",
    "        # Get the data over the masked period\n",
    "        tinds = data.loc[mask].index\n",
    "    \n",
    "        # Now we're going to average all the values of var that match with the timestep indices that we've just found\n",
    "        # The nanmean function means that any missing data ('NaNs, or Not-a-Numbers') are ignored in the average.\n",
    "        halfhourvar.append(np.nanmean(data[var][np.squeeze(tinds)]))\n",
    "        halfhourts.append(tstart + pandas.Timedelta(minutes=15))\n",
    "        #print('half-hour average: ', np.nanmean(data[var][np.squeeze(tinds)]))\n",
    "        tstart = tend\n",
    "    \n",
    "    # Change the name so instead of _CSAT the name has 'hh' (E.g. 'Ux_CSAT' -> 'Uxhh')\n",
    "    new_name = var.replace('_CSAT', 'hh')\n",
    "    # Return our half-hour averages in a pandas dataframe\n",
    "    return pandas.DataFrame({'TIMESTAMP':halfhourts, new_name:halfhourvar})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's time to try your half-hour averaging machine. We're going to give it the dataframe, and the variable that we want to create half-hour averages of."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "Vertical_velocity_hh = do_half_hour_avs(df, var = 'Vertical_velocity')\n",
    "Theta_hh = do_half_hour_avs(df, var = 'Theta')\n",
    "Mixing_ratio_hh = do_half_hour_avs(df, var = 'Mixing_ratio')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make a plot of the original data and the half-hour averages, on the same axes, for ONE of the variables (your choice which one)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_anomalies(data, var, varhh): # <- don't forget the : after your function definition\n",
    "    '''\n",
    "    Anomaly calculation function: \n",
    "    Inputs: The data frame, and the variable that we would like to return the anomalies values of\n",
    "    Outputs: The anomalies.\n",
    "    '''\n",
    "    \n",
    "    # Define an empty array to store hour half-hour averages in\n",
    "\n",
    "    anom = np.empty(len(data[var]))\n",
    "\n",
    "    # Let's start at the start of the dataset\n",
    "    tstart = data.TIMESTAMP[0]\n",
    "    \n",
    "    # Get the 'TIMESTAMP' and var columns from the dataframe.\n",
    "    data = data[['TIMESTAMP', var]]\n",
    "\n",
    "    # Now, we're going to loop through each half hour of the 24-hour period. \n",
    "    for nseg in np.arange(0,48):\n",
    "        \n",
    "        # The end of the half-hour period is 30 minutes after the start of the half-hour period\n",
    "        tend = tstart + pandas.Timedelta(minutes=30)\n",
    "        #print('Calculating averages for half hour between', np.str(tstart), ' and ', np.str(tend))\n",
    "\n",
    "        # Make a mask for the 30 minute period between dstart and dend\n",
    "        mask = (data['TIMESTAMP'] >= tstart) & (data['TIMESTAMP'] < tend)\n",
    "        \n",
    "        # Get the data over the masked period\n",
    "        tinds = data.loc[mask].index\n",
    "    \n",
    "        # Now we're going to calculate the anomalies\n",
    "        anom[tinds] = data[var][tinds] - varhh[nseg]\n",
    "        tstart = tend\n",
    "    \n",
    "    \n",
    "    # Return othe anomalies\n",
    "    return anom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Theta_anom = calculate_anomalies(df, 'Theta', Theta_hh.Theta)\n",
    "Mixing_ratio_anom = calculate_anomalies(df, 'Mixing_ratio', Mixing_ratio_hh.Mixing_ratio)\n",
    "Vertical_velocity_anom = calculate_anomalies(df, 'Vertical_velocity', Vertical_velocity_hh.Vertical_velocity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make a plot of the anomalies for one of the variables (your choice which one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now it's time to calculate some fluxes! \n",
    "\n",
    "First, you have to multiple two of your anomaly terms together:\n",
    "\n",
    "$\\overline{w' \\theta'}$ and $\\overline{w' q'}$\n",
    "\n",
    "Next, you have to calculate the half-hour average of this. Add it to the original pandas data frame, and then use the half-hour averaging function. \n",
    "\n",
    "Finally, you have to apply a couple of constants to find the sensible and latent heat fluxes. It's OK to assume that density is a constant = 1.25 kg/m^3. \n",
    "\n",
    "$Q_H = \\rho c_p \\overline{w' \\theta'}$\n",
    "$Q_E = \\rho L_v \\overline{w' q'}$\n",
    "\n",
    "\n",
    "## Don't over-think this step. It's just a few of lines of code. If you find yourself trying to do anything too complicated, you've probably missed the point. Ask for help! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now plot your sensible and latent heat flux, and answer the questions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Surface Energy Balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the fluxes. They will load in the form of an array of size 365 X 48. That is one row for every day of the year, and one \n",
    "# column for every half-hour period the day. \n",
    "\n",
    "SWD = pandas.read_csv('/home/workbooks/fluxes_week8-9/SWD.csv', header=None).values\n",
    "LWD = pandas.read_csv('/home/workbooks/fluxes_week8-9/LWD.csv', header=None).values\n",
    "SWU = pandas.read_csv('/home/workbooks/fluxes_week8-9/SWU.csv', header=None).values\n",
    "LWU = pandas.read_csv('/home/workbooks/fluxes_week8-9/LWU.csv', header=None).values\n",
    "QH = pandas.read_csv('/home/workbooks/fluxes_week8-9/QH.csv', header=None).values\n",
    "QE = pandas.read_csv('/home/workbooks/fluxes_week8-9/QE.csv', header=None).values\n",
    "QG = pandas.read_csv('/home//workbooks/fluxes_week8-9/QG.csv', header=None).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot all seven terms of the surface energy balance on one plot. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now calculate Q* from (a) the sum of the radiative fluxes and (b) the sum of the sensible, latent and ground heat fluxes. \n",
    "# Plot the two calculations of Q* on the same axes. Careful with signs! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
